{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembling your MLP\n",
    "\n",
    "As mentioned in the previous challenge, the missing brick for you to be able to update your MLP parameters during training is to backpropagate our update computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:15:52.566994Z",
     "start_time": "2018-12-15T13:15:52.515278Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss minimization\n",
    "\n",
    "Using the previous matrix understanding of a layer forward operation:\n",
    "$$ \\forall\\ W\\ \\in\\ \\mathbb{M}_{M,N}(\\mathbb{R}), \\forall\\ b\\ \\in\\ \\mathbb{R}^M, \\forall\\ X\\ \\in\\ \\mathbb{R}^N,\\ f(X) = activation(WX + b) $$\n",
    "\n",
    "Assuming that we expected the output to be $y \\in \\mathbb{R}$, we can define a loss function, Mean Squared Errors (MSE) in this case:\n",
    "\n",
    "$$ \\forall y \\in \\mathbb{R}^M, \\forall X \\in \\mathbb{R}^N, L(X, y) = \\frac{1}{M} \\sum_{i=1}^M (f(X)_i - y_i)^2\n",
    "= \\frac{1}{M} (f(X) - y)^T * (f(X) - y)\n",
    "$$\n",
    "\n",
    "Further resources on loss functions:\n",
    "- Loss functions for different problems: [Christopher Bourez's blog](http://christopher5106.github.io/deep/learning/2016/09/16/about-loss-functions-multinomial-logistic-logarithm-cross-entropy-square-errors-euclidian-absolute-frobenius-hinge.html)\n",
    "- Debunking loss functions in deep learning: shorter but better illustrated [Medium article](https://medium.com/@dmitrijtichonov/debunking-loss-functions-in-deep-learning-4b9abc4c8d4c) by Dmitrij Tichonov\n",
    "\n",
    "Since we will be optimizing the parameters of our MLP relatively to the loss, we will need a function to compute it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:15:52.571479Z",
     "start_time": "2018-12-15T13:15:52.568348Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_loss(expected, output):\n",
    "    \"\"\"\n",
    "    Compute the loss for a given expected and computed output\n",
    "    Args:\n",
    "        expected (np.array): 1D-numpy array\n",
    "        output (np.array): 1D-numpy array of same size as expected\n",
    "    Returns:\n",
    "        loss (float): loss respective to expected and output\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: compute the MSE loss\n",
    "    squared_errors = None\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the returned object is a scalar, and since we initialize the inputs between 0 and 1, the loss should be as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:15:52.578238Z",
     "start_time": "2018-12-15T13:15:52.574020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21204441770908766\n"
     ]
    }
   ],
   "source": [
    "output_size = 8\n",
    "# Random values for loss computation\n",
    "output_values = np.random.rand(output_size)\n",
    "expected_values = np.random.rand(output_size)\n",
    "\n",
    "print(compute_loss(expected_values, output_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective is to minimize the Loss to be as close as possible to y, and in order to find a minimum, what better option is there than derivation.\n",
    "\n",
    "As we aim at finding minima of the loss function (where the gradient of the loss function is zero), we will update our weights as follows:\n",
    "$$ W \\leftarrow W - \\alpha \\frac{\\partial L(X,y)}{\\partial W} = W - \\alpha \\nabla_L(X,y) $$\n",
    "where $\\alpha$ is called the learning rate and $\\nabla_L \\in \\mathbb{M}_{M,N}(\\mathbb{R})$ represents the gradient of L relatively to the weights.\n",
    "\n",
    "![Gradient descent](https://cdn-images-1.medium.com/max/800/1*HrFZV7pKPcc5dzLaWvngtQ.png \"Gradient descent on loss\")\n",
    "*Source: http://sebastianraschka.com/ — Python Machine Learning, 2nd Edition*\n",
    "\n",
    "More specifically, the gradient is a differential operator for multi-variate functions. This specific optimizer is a basic Gradient Descent. There are many other optimizers available, check the following resources:\n",
    "- List of illustrated optimizers: [Medium article](https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f) by Anish Singh Walia, and [blog post](http://ruder.io/optimizing-gradient-descent/) by Sebastian Ruder\n",
    "- Deep Learning book by Ian Goodfellow: [Optimization for training Deep Learning](https://www.deeplearningbook.org/contents/optimization.html)\n",
    "- Highlights of 2017 for deep learning optimization: [recent updates](http://ruder.io/deep-learning-optimization-2017/)\n",
    "- 3Blue1Brown videos: [Gradient Descent](https://www.youtube.com/watch?v=IHZwWFHWa-w&t=1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A single perceptron update\n",
    "\n",
    "Let's take a step back to our single perceptron model with a forward operation $f: \\mathbb{R}^N \\rightarrow \\mathbb{R}$\n",
    "$$ \\forall X \\in\\ \\mathbb{R}^N,\\ f(X) = activation\\Bigg(\\Big(\\sum_{i=1}^{N} W_i * X_i\\Big) + b\\Bigg) $$\n",
    "\n",
    "As we have a single perceptron, there is only one term in the sum of the loss function:\n",
    "\n",
    "$$ \\forall y \\in \\mathbb{R}, \\forall X \\in \\mathbb{R}^N, L(X, y) = (f(X) - y)^2 $$\n",
    "\n",
    "In order to compute the gradient, we are going to need partial derivatives of f. But since it's a composed function, the chain rule is going to be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain rule\n",
    "In this challenge, we will have to compute derivatives of complex functions. One can compute the derivative of a composed functions using the chain rule. If we define the function f as being the composition of g by h, on a given space called E:\n",
    "$$ \\forall x \\in E,\\ f(x) = h(g(x)) $$\n",
    "then\n",
    "$$ \\forall x \\in E, f'(x) = \\frac{df}{dx}(x) = \\frac{dh}{dg(x)}(g(x)) * \\frac{dg}{dx}(x) = h'(g(x)) * g'(x) $$\n",
    "\n",
    "Time to get to work, let's find the gradient of our loss function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\forall y \\in \\mathbb{R}, \\forall X \\in \\mathbb{R}^N,\\ \n",
    "\\forall i \\in [1, N],$$\n",
    "$$\n",
    "\\frac{\\partial L(X, y)}{\\partial W_i} = \\frac{\\partial}{\\partial W_i}(f(X) - y)^2\n",
    "= 2(f(X) - y)\\frac{\\partial f(X)}{\\partial W_i}\n",
    "$$\n",
    "\n",
    "Interesting, we now have to calculate the partial derivative of the forward function:\n",
    "\n",
    "$$ \\forall X \\in\\ \\mathbb{R}^N,\\ \\forall i \\in [1, N],$$\n",
    "$$\n",
    "\\frac{\\partial f(X)}{\\partial W_i} = \n",
    "activation'\\Bigg(\\Big(\\sum_{j=1}^{N} W_j * X_j\\Big) + b\\Bigg) * \n",
    "\\frac{\\partial}{\\partial W_i}\\Bigg(\\Big(\\sum_{j=1}^{N} W_j * X_j\\Big) + b\\Bigg) = activation'\\Bigg(\\Big(\\sum_{j=1}^{N} W_j * X_j\\Big) + b\\Bigg) * X_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in a nutshell,\n",
    "$$ \\forall y \\in \\mathbb{R}, \\forall X \\in \\mathbb{R}^N,\\ \\forall i \\in [1, N],$$\n",
    "$$\n",
    "\\frac{\\partial L(X, y)}{\\partial W_i} = 2(f(X) - y) * activation'\\Bigg(\\Big(\\sum_{j=1}^{N} W_j * X_j\\Big) + b\\Bigg)*X_i\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L(X, y)}{\\partial b} = 2(f(X) - y) * activation'\\Bigg(\\Big(\\sum_{j=1}^{N} W_j * X_j\\Big) + b\\Bigg)\n",
    "$$\n",
    "\n",
    "- as we have already computed the weighted sum with the bias on the forward pass, the only unknown here is the derivative of the activation function\n",
    "- since the activation is predefined when we create our MLP, we can express analytically its derivative and predefined it just like the activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An activation example\n",
    "First let's take back the sigmoid $\\sigma$ as an activation function and it's derivative $\\sigma': \\mathbb{R} \\rightarrow \\mathbb{R}$, \n",
    "\n",
    "$$ \\forall\\ x \\in \\mathbb{R},\\ \\sigma'(x) = \\frac{d\\sigma}{dx}(x) = \\frac{d}{dx}\\Bigg(\\frac{1}{1 + e^{-x}}\\Bigg) = \\frac{e^{-x}}{(1 + e^{-x})^2} = \\sigma(x) \\frac{e^{-x}}{1 + e^{-x}} = \\sigma(x) \\frac{(1 + e^{-x}) - 1}{1 + e^{-x}} $$\n",
    "$$ \\forall\\ x \\in \\mathbb{R},\\ \\sigma'(x) = \\frac{d\\sigma}{dx}(x) = \\sigma(x) (1 - \\sigma(x)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:15:52.585125Z",
     "start_time": "2018-12-15T13:15:52.580957Z"
    }
   },
   "outputs": [],
   "source": [
    "## TODO: define right here the expressions of sigmoid and sigmoid_prime \n",
    "def sigmoid(x): return 0\n",
    "def sigmoid_prime(x): return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using what we said about predefining both the activation and its derivative, edit the Activation class constructor and methods of the perceptron.py file. Let the inputs (0) as is, since it's easier to check the value of the sigmoid in zero than other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:15:52.592439Z",
     "start_time": "2018-12-15T13:15:52.587431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.25\n"
     ]
    }
   ],
   "source": [
    "## TODO: edit the Activation methods __init__, forward and prime\n",
    "from perceptron import Activation\n",
    "activation = Activation(sigmoid, sigmoid_prime)\n",
    "print(activation.forward(0), activation.prime(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a more versatile object for activation, we need to work on the weight update.\n",
    "During the forward pass, as we compute the weighted sum with the bias, we will store the value of $\\sigma'$ for this weighted sum. Edit the Perceptron class constructor and methods of the perceptron.py file by following the instructions in comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:15:52.597546Z",
     "start_time": "2018-12-15T13:15:52.594463Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 16\n",
    "## TODO: edit the Perceptron methods __init__, forward, backward, update_params()\n",
    "from perceptron import Perceptron\n",
    "p = Perceptron(input_size, activation=activation, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test your implementation by performing a small training sequence. For further tests, we will use the [fastprogress](https://github.com/fastai/fastprogress) library to track our progress during training. In this notebook, we will not consider monitoring the validation loss or concern about overfitting, but only about the convergence of our training loss to a minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:15:53.206146Z",
     "start_time": "2018-12-15T13:15:52.599040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:00 <p>Epoch 1: MSE 0.171850811574584<p>Epoch 2: MSE 0.14922444082418687<p>Epoch 3: MSE 0.11881777370601361<p>Epoch 4: MSE 0.08355411527093769<p>Epoch 5: MSE 0.052265152176961566<p>Epoch 6: MSE 0.03220932466875882<p>Epoch 7: MSE 0.02237846966327487<p>Epoch 8: MSE 0.018215773408956214<p>Epoch 9: MSE 0.016499432578115324<p>Epoch 10: MSE 0.01572802148538607<p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastprogress import master_bar, progress_bar\n",
    "# Hyperparameters (feel free to change them)\n",
    "alpha = 1e-3\n",
    "nb_iterations = 1000\n",
    "nb_epochs = 10\n",
    "\n",
    "# Inputs & expected outputs\n",
    "inputs = np.random.rand(nb_iterations, input_size)\n",
    "# Let's try to approximate the normalized sum (mean) of the input\n",
    "# Note: we can't just sum as the perceptron output is squeezed by our activation choice\n",
    "# Note: feel free to change the activation to ReLU for instance\n",
    "y = inputs.sum(axis=1) / inputs.shape[1]\n",
    "# Training Loop\n",
    "mb = master_bar(range(nb_epochs))\n",
    "for epoch in mb:\n",
    "    loss = 0\n",
    "    for iter_idx in progress_bar(range(nb_iterations), parent=mb):\n",
    "        # TODO: forward the input\n",
    "        output = None\n",
    "        # TODO: backpropagate the gradient of the loss\n",
    "        p.backward(None)\n",
    "        # TODO: update the weights and bias of the perceptron\n",
    "        p.update_params(0)\n",
    "        # TODO: update the total loss (do not divide by the number of terms)\n",
    "        loss += 0\n",
    "        mb.child.comment = f\"running loss {loss / float(iter_idx + 1)}\"\n",
    "    mb.first_bar.comment = f\"completed epoch {epoch+1}\"\n",
    "    mb.write(f\"Epoch {epoch+1}: MSE {loss / float(nb_iterations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You managed to run your first training for your own perceptron, congratulations! Perhaps you feel like we should upgrade to something closer to an MLP? Well, that's exactly what we are going to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let an MLP of K layers with their respective:\n",
    "- width $(s_l)_{l \\in [1,K]} \\in \\mathbb{N}^K$ (we'll note $s_0$ the number of inputs of the first layer), \n",
    "- weights $(W_l)_{l \\in [1,K]} = ((w_{l,i,j})_{(i,j) \\in [1, s_l] \\times [1, s_{l-1}]})_{l \\in [1,K]}$,\n",
    "- biases $(B_l)_{l \\in [1,K]} = ((b_{l,i})_{i \\in [1, s_l]})_{l \\in [1,K]}$,\n",
    "- layer activation values $(A_l)_{l \\in [1, K]} = ((a_{l,i})_{i \\in [1, s_l]})_{l \\in [1,K]}$,\n",
    "- weighted sum with bias $ (Z_l)_{l \\in [1,K]} = ((z_{l,i})_{i \\in [1, s_l]})_{l \\in [1,K]} = (W_l A_{l-1} + B_l)_{l \\in [1,K]}$\n",
    "\n",
    "![MLP](http://pubs.sciepub.com/ajmm/3/3/1/bigimage/fig5.png \"Multi-layer perceptron\")\n",
    "*Source: Science and Education Publishing*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T14:13:11.198701Z",
     "start_time": "2018-12-13T14:13:11.185206Z"
    }
   },
   "source": [
    "So more generally, we can define our update rule for every weight matrix in our MLP.\n",
    "$$\n",
    "\\forall l \\in [1, K],\\\n",
    "W_l \\leftarrow W_l - \\alpha \\frac{\\partial L(X,y)}{\\partial W_l} = W_l - \\alpha \\nabla_L^l(X, y) $$\n",
    "where $\\nabla_L^l$ represents the gradient of the loss L relatively to the weights of layer l.\n",
    "\n",
    "$$\n",
    "\\forall l \\in [1, K],\\\n",
    "\\forall y \\in \\mathbb{R}^{S_K}, \\forall X \\in \\mathbb{R}^{S_0},\\ $$\n",
    "$$\n",
    "\\nabla_L^l(X, y) = \\begin{bmatrix}\n",
    "    \\frac{\\partial L(X,y)}{\\partial w_{l,1,1}} & \\cdots & \\frac{\\partial L(X,y)}{\\partial w_{l,1,s_{l-1}}} \\\\\n",
    "    \\vdots & & \\vdots \\\\\n",
    "    \\frac{\\partial L(X,y)}{\\partial w_{l,s_l,1}} & \\cdots & \\frac{\\partial L(X,y)}{\\partial w_{l,s_l,s_{l-1}}}\n",
    "\\end{bmatrix} = \\Big(\\frac{\\partial L(X,y)}{\\partial w_{l,i,j}}\\Big)_{(i,j) \\in [1,s_{l-1}] \\times [1,s_l]} $$\n",
    "\n",
    "Here is a list of resources you might want to check for matrix calculus:\n",
    "- Videos: Ben Lambert [Part 1](https://www.youtube.com/watch?v=iWxY7VdcSH8) [Part 2](https://www.youtube.com/watch?v=uoejt0FCWWA) [Part 3](https://www.youtube.com/watch?v=i6fqfH5hx60)\n",
    "- Lecture: National University of Singapore [Matrix Differentiation](https://www.comp.nus.edu.sg/~cs5240/lecture/matrix-differentiation.pdf)\n",
    "- Notes: University of Minnesota [Matrix differentiation](https://atmos.washington.edu/~dennis/MatrixCalculus.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Backpropagation](https://cdn-images-1.medium.com/max/1600/1*FceBJSJ7j8jHjb4TmLV0Ew.png \"Backpropagation illustration\")\n",
    "\n",
    "*Source: Stanford CS231n - Lecture 4*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our first definition of the loss function with our updated notation,\n",
    "$$\n",
    "\\forall X \\in \\mathbb{R}^{s_0}, \\forall y \\in \\mathbb{R}^{s_K},\n",
    "L(X, y) = \\frac{1}{s_K} \\sum_{j=0}^{s_K} (a_{K,j} - y_j)^2\n",
    "$$\n",
    "\n",
    "Fortunately, with the chain rule, we can express this loss gradient in a more convenient way:\n",
    "\n",
    "$$ \n",
    "\\forall X \\in \\mathbb{R}^{s_0}, \\forall y \\in \\mathbb{R}^{s_K}, \\forall l \\in [1, K],\\\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L(X, y)}{\\partial W_l} = \\frac{\\partial L(X, y)}{\\partial A_K} \\frac{\\partial A_K}{\\partial W_l}\n",
    "= \\frac{1}{s_K} \\Bigg(\\frac{\\partial}{\\partial a_{K,i}} \\Bigg(\\sum_{j=1}^{s_K} (a_{K,j}(X) - y_j)^2 \\Bigg)\\Bigg)_{i \\in [1, s_K]} \\frac{\\partial A_K}{\\partial W_l}\n",
    "$$\n",
    "$$\n",
    "= \\frac{1}{s_K} \\Bigg(\\frac{\\partial}{\\partial a_{K,i}} \\Bigg((a_{K,i}(X) - y_i)^2 \\Bigg)\\Bigg)_{i \\in [1, s_K]} \\frac{\\partial A_K}{\\partial W_l}\n",
    "$$\n",
    "\n",
    "Thus by introducing the error $ \\mathcal{E}(X,y) = (\\epsilon_i(X,y_i))_{i \\in [1, s_K]} = (a_{K,i}(X) - y_i)_{i \\in [1, s_K]}$,\n",
    "\n",
    "$$ \n",
    "\\forall X \\in \\mathbb{R}^{s_0}, \\forall y \\in \\mathbb{R}^{s_K}, \\forall l \\in [1, K],\\\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L(X, y)}{\\partial W_l} = \\frac{2}{s_K} \\Big(\\epsilon_i(X,y_i)\\Big)_{i \\in [1, s_K]} \\frac{\\partial A_K}{\\partial W_l}\n",
    "= \\frac{2}{s_K} \\mathcal{E}(X,y) \\frac{\\partial A_K}{\\partial W_l}\n",
    "$$\n",
    "\n",
    "The last part of the expression shows that the gradient of the loss function is directly related to the gradient of the forward function. This will allow us to update the last layer parameters but we will to backpropagate the gradient further to update earlier layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Graph\n",
    "\n",
    "As we will need to recurrently calculate the gradient relatively to the weights and biases for updating our MLP parameters, the notion of a computational graph is extremely useful.\n",
    "\n",
    "![Computational graph](https://cdn-images-1.medium.com/max/1400/1*UATNEUQ0dKbvDdI79y3z9A.png \"Computational graph\")\n",
    "\n",
    "*Source: Manik Sonik - Hackernoon: Exploding And Vanishing Gradient Problem: Math Behind The Truth*\n",
    "\n",
    "The core idea is to decompose the function performed by the entire MLP into elementary operations *(cf. the 4-layer MLP above)*. In our case, the operations are:\n",
    "- Matrix by vector multiplication (on weights and inputs)\n",
    "- Vectors' sum (on the weighted sum and the bias)\n",
    "- Activation (on the $(Z_l)_{l \\in [1, K]}$)\n",
    "\n",
    "Iteratively you can map the entire MLP with these operations, that are individually easy to calculate the gradient of. Here is an excellent resource about backpropagation:\n",
    "\n",
    "- 3Blue1Brown videos: [Introducation to backpropagation](https://www.youtube.com/watch?v=Ilg3gGewQ5U) [Backpropagation calculus](https://www.youtube.com/watch?v=tIeHLnjs5U8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagating gradients through the computational graph\n",
    "\n",
    "Using the chain rule, we are going to need the relation between the partial derivative of the loss function relatively to a given layer's parameters ($W_l, B_l$) & inputs ($A_{l-1}$), and the one relatively to the previous layer's parameters & inputs.\n",
    "\n",
    "First, we need to derive through the activation gate:\n",
    "$$\n",
    "\\forall X \\in \\mathbb{R}^{s_0}, \\forall y \\in \\mathbb{R}^{s_K}, \\forall l \\in [1, K],\n",
    "\\frac{\\partial L(X,y)}{\\partial Z_l} = \\frac{\\partial L(X,y)}{\\partial A_l} \\frac{\\partial A_l}{\\partial Z_l} = \\frac{\\partial L(X,y)}{\\partial A_l} activation'(Z_l)\n",
    "$$\n",
    "\n",
    "We will use the Kronecker symbol $\\delta_{ij}$ where $(i,j) \\in \\mathbb{N}^2$ ,that is equal to 1 if and only if $i=j$. Now using the chain rule, we can use the result to limit computation for the other gradients:\n",
    "\n",
    "$$\n",
    "\\forall X \\in \\mathbb{R}^{s_0}, \\forall y \\in \\mathbb{R}^{s_K}, \\forall l \\in [1, K],\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L(X,y)}{\\partial W_l} = \\frac{\\partial L(X,y)}{\\partial Z_l} \\frac{\\partial Z_l}{\\partial W_l}\n",
    "= \\frac{\\partial L(X,y)}{\\partial Z_l} \\Big(\\frac{\\partial z_{l,i}}{\\partial w_{l,j,k}}\\Big)_{(i,j,k) \\in [1, s_l]^2 \\times [1, s_{l-1}]}\n",
    "= \\frac{\\partial L(X,y)}{\\partial Z_l} \\Big(\\delta_{ij} a_{l-1,k}\\Big)_{(i,j,k) \\in [1, s_l]^2 \\times [1, s_{l-1}]}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L(X,y)}{\\partial B_l} = \\frac{\\partial L(X,y)}{\\partial Z_l} \\frac{\\partial Z_l}{\\partial B_l}\n",
    "= \\frac{\\partial L(X,y)}{\\partial Z_l} \\Big(\\frac{\\partial z_{l,i}}{\\partial b_{l,j}}\\Big)_{(i,j) \\in [1, s_l]^2}\n",
    "= \\frac{\\partial L(X,y)}{\\partial Z_l} (\\delta_{ij})_{(i,j) \\in [1, s_l]^2}\n",
    "= \\frac{\\partial L(X,y)}{\\partial Z_l} I_{s_l} = \\frac{\\partial L(X,y)}{\\partial Z_l}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L(X,y)}{\\partial A_{l-1}} = \\frac{\\partial L(X,y)}{\\partial Z_l} \\frac{\\partial Z_l}{\\partial A_{l-1}}\n",
    "= \\frac{\\partial L(X,y)}{\\partial Z_l} \\Big(\\frac{\\partial z_{l,i}}{\\partial a_{l-1,j}}\\Big)_{(i,j) \\in [1, s_l]^2}\n",
    "= \\frac{\\partial L(X,y)}{\\partial Z_l} \\Big(w_{l,i,j}\\Big)_{(i,j) \\in [1, s_l]^2}\n",
    "= \\frac{\\partial L(X,y)}{\\partial Z_l} W_l\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, by recurrence, starting from $A_K$, we multiply the current gradient of the loss by:\n",
    "- $activation'(Z_l)$ to get the gradient relatively to bias\n",
    "- $activation'(Z_l) \\Big(\\delta_{ij} a_{l-1,k}\\Big)_{(i,j,k) \\in [1, s_l]^2 \\times [1, s_{l-1}]}$ to get the gradient relatively to weights\n",
    "- $activation'(Z_l) W_l$ to get the one for the previous layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $\\Big(\\delta_{ij} a_{l-1,k}\\Big)_{(i,j,k) \\in [1, s_l]^2 \\times [1, s_{l-1}]}$ is a 3D-tensor, just like multi-channel image data. But here it would have $s_{l-1}$ channels, and on a given channel $ k \\in [1, s_{l-1}]$, it would look like this:\n",
    "\n",
    "$$\n",
    "\\Big(\\delta_{ij} a_{l-1,k}\\Big)_{(i,j) \\in [1, s_l]^2} =\n",
    "\\begin{bmatrix}\n",
    "    a_{l-1,k} & & \\mathbb{0} \\\\\n",
    "     & \\ddots & \\\\\n",
    "    \\mathbb{0} & & a_{l-1,k}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Keep that in mind when you will compute the loss gradient relatively to the weights *(as it is 3-dimensional, the numpy.matmul will not work, you should check the [numpy.tensordot](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.tensordot.html) function instead)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer update\n",
    "Let's start with a single layer and implement each method. \n",
    "\n",
    "Edit the constructor, forward, backward and update_params methods of the Layer class in the mlp.py file (you can copy paste your implementation of the Activation class from perceptron.py). Make sure to read carefully the instructions as you might end up with dimension mismatch at some point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:15:53.213339Z",
     "start_time": "2018-12-15T13:15:53.208816Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 16\n",
    "output_size = 8\n",
    "## TODO: edit the Layer methods __init__, forward, backward and update_params\n",
    "from mlp import Layer\n",
    "l = Layer(input_size, output_size, activation=activation, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will test the dimensions of your network output and of the backpropagated gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:15:53.220437Z",
     "start_time": "2018-12-15T13:15:53.215284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, alright, alright\n"
     ]
    }
   ],
   "source": [
    "# Inputs & expected outputs\n",
    "inputs = np.random.rand(input_size)\n",
    "# Let's take the sum function as target\n",
    "expected = inputs.sum() * np.ones(output_size)\n",
    "# Forward\n",
    "output = l.forward(inputs)\n",
    "# Check if you output and backpropagated gradient dimensions are correct\n",
    "assert output.size == output_size\n",
    "assert l.backward(2. / output.size * (output - expected)).size == input_size\n",
    "print(\"Alright, alright, alright\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent work, we are almost there!\n",
    "Now we have to be able to stack layers consecutively and perform the same forward and backward to train our MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The MLP strikes back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:15:53.225836Z",
     "start_time": "2018-12-15T13:15:53.222429Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choose the number of inputs (feel free to change this)\n",
    "input_size = 8\n",
    "output_size = 8\n",
    "inputs = np.random.rand(input_size)\n",
    "expected = np.random.rand(output_size)\n",
    "# We'll define the number of units in each consecutive layer (feel free to change this)\n",
    "layer_output_sizes = [64, 32, 32, 32, output_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the part where you just have to use your previous methods of each layer smartly to give a coherence to your MLP. Edit the constructor, forward, backward and update_params methods of the MLP class in the mlp.py file. Again, the instructions will hopefully guide you towards a good implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:15:53.230976Z",
     "start_time": "2018-12-15T13:15:53.227774Z"
    }
   },
   "outputs": [],
   "source": [
    "## TODO: edit the MLP methods __init__ and forward to compute the correct network output\n",
    "from mlp import MLP\n",
    "mlp = MLP(input_size, layer_output_sizes, activation=activation, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train this network!\n",
    "With all the work you have done, you will notice that it does not take more python lines to run a training here than with common deep learning frameworks. Just a last effort to get this training started by following the instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:16:14.543628Z",
     "start_time": "2018-12-15T13:15:53.233078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:21 <p>Epoch 1: MSE 0.18697264827845977<p>Epoch 2: MSE 0.17547339263353895<p>Epoch 3: MSE 0.16535809237273863<p>Epoch 4: MSE 0.15665013105002712<p>Epoch 5: MSE 0.1494238030996485<p>Epoch 6: MSE 0.14378791800694937<p>Epoch 7: MSE 0.13964336624849205<p>Epoch 8: MSE 0.13664433940980902<p>Epoch 9: MSE 0.13435918324513643<p>Epoch 10: MSE 0.13241184092928704<p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastprogress import master_bar, progress_bar\n",
    "# Hyperparameters (feel free to change them)\n",
    "alpha = 1e-3\n",
    "nb_iterations = 1000\n",
    "nb_epochs = 10\n",
    "\n",
    "# Inputs & expected outputs\n",
    "inputs = np.random.rand(nb_iterations, input_size)\n",
    "# Training Loop\n",
    "mb = master_bar(range(nb_epochs))\n",
    "for epoch in mb:\n",
    "    loss = 0\n",
    "    for iter_idx in progress_bar(range(nb_iterations), parent=mb):\n",
    "        # Let's approximate the identity function\n",
    "        expected = inputs[iter_idx]\n",
    "        # TODO: forward the input\n",
    "        outputs = None\n",
    "        # TODO: backpropagate the loss gradient\n",
    "        mlp.backward(None)\n",
    "        # TODO: update the MLP parameters\n",
    "        mlp.update_params(0)\n",
    "        # TODO: update the total loss (do not divide by the number of terms)\n",
    "        loss += 0\n",
    "        mb.child.comment = f\"running loss {loss / float(outputs.size * (iter_idx + 1))}\"\n",
    "    mb.first_bar.comment = f\"completed epoch {epoch+1}\"\n",
    "    mb.write(f\"Epoch {epoch+1}: MSE {loss / float(outputs.size * nb_iterations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, you really deserve a treat!\n",
    "With all your work, you are now able to implement fully connected layers, activation, and backpropagation for a full MLP network. In the same time, you gain (hopefully) better knowledge about the linear algebra and calculus hidden behind those with the computational graph and the implications of the chain rule.\n",
    "\n",
    "Congratulations again, have a well-deserved rest!\n",
    "\n",
    "*Spoiler alert: it's just the beginning of the journey as there are many other layers that compose common deep learning architectures and other optimizers. But from now on, you will only have to apply the same logic and think about how to implement the forward method and how to backpropagate through the operator gate*\n",
    "\n",
    "![Most interesting man](https://i.imgflip.com/2p0lib.jpg \"Most interesting man\")\n",
    "*Source: imgflip.com*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
